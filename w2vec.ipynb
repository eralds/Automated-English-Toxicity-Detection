{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "import torch\n",
    "import csv\n",
    "from gensim.models import KeyedVectors"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T08:50:53.918813Z",
     "start_time": "2024-04-19T08:50:53.815258Z"
    }
   },
   "id": "1a00f61be8b23a0e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reading the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f610464aa2d40706"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train_2024.csv\", quoting=csv.QUOTE_NONE)\n",
    "val_df = pd.read_csv(\"dev_2024.csv\", quoting=csv.QUOTE_NONE)\n",
    "test_def = pd.read_csv(\"test_2024.csv\", quoting=csv.QUOTE_NONE)\n",
    "\n",
    "train_text = train_df[\"text\"].values\n",
    "y_train = torch.tensor(train_df[\"label\"].values)\n",
    "\n",
    "val_text = val_df[\"text\"].values\n",
    "y_val = torch.tensor(val_df[\"label\"].values)\n",
    "\n",
    "test_text = test_def[\"text\"].values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T08:50:54.407989Z",
     "start_time": "2024-04-19T08:50:53.876544Z"
    }
   },
   "id": "3c5ee1b14f29f00e"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update(punctuation)  \n",
    "stop_words.add(\"...\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T08:50:54.415238Z",
     "start_time": "2024-04-19T08:50:54.409579Z"
    }
   },
   "id": "9839065348e65384"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cleaning and Tokenization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec6831cb2b916071"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "def clean_and_tokenize(df, stopwords):\n",
    "    tokens_list = [word_tokenize(i) for i in df]\n",
    "\n",
    "    lc_tokens_list = []    \n",
    "    for i in tokens_list: \n",
    "        lc_tokens_list.append([token.lower() for token in i]) \n",
    "        \n",
    "    filtered_sentence = []    \n",
    "    for i in lc_tokens_list: \n",
    "        filtered_sentence.append([token for token in i if token not in stopwords]) \n",
    "        \n",
    "    return filtered_sentence"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T08:50:54.421951Z",
     "start_time": "2024-04-19T08:50:54.417207Z"
    }
   },
   "id": "ce220e7a0968789c"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "filtered_sentence_train = clean_and_tokenize(train_text, stop_words)\n",
    "filtered_sentence_val = clean_and_tokenize(val_text, stop_words)\n",
    "filtered_sentence_test = clean_and_tokenize(test_text, stop_words)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T08:51:19.679835Z",
     "start_time": "2024-04-19T08:50:54.438815Z"
    }
   },
   "id": "7ba2e5ea10c63abe"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading the pre-trained Wikipedia2Vec model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb74569a12a2f2dd"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "wv_model = KeyedVectors.load_word2vec_format('enwiki_20180420_100d.txt.bz2', binary=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T08:55:43.252408Z",
     "start_time": "2024-04-19T08:51:19.680712Z"
    }
   },
   "id": "39f5ffdfaecfd5c0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generating embeddings"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1c36192d3bd8531"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def generate_embeddings(filtered_sentence):\n",
    "    \n",
    "    sentence_embeddings = []\n",
    "    \n",
    "    missing_embeddings_ids = []\n",
    "    available_embeddings = []\n",
    "\n",
    "    \n",
    "    for i in range(len(filtered_sentence)):\n",
    "\n",
    "        embeddings_for_one_sentence = []\n",
    "    \n",
    "        current_sentence = filtered_sentence[i]\n",
    "        for j in range(len(current_sentence)):\n",
    "            try:\n",
    "                word_vector = wv_model.get_vector(current_sentence[j])\n",
    "                embeddings_for_one_sentence.append(word_vector)\n",
    "            except KeyError:\n",
    "                pass\n",
    "        \n",
    "        if len(embeddings_for_one_sentence) == 0:\n",
    "            missing_embeddings_ids.append(i)\n",
    "            sentence_embeddings.append([0])\n",
    "        else:\n",
    "            embedding_mean = np.mean(embeddings_for_one_sentence, axis=0)\n",
    "            sentence_embeddings.append(embedding_mean)\n",
    "            available_embeddings.append(embedding_mean)\n",
    "            \n",
    "    for i in missing_embeddings_ids:\n",
    "        average_sentence_embedding = np.mean(available_embeddings, axis=0)\n",
    "        sentence_embeddings[i] = average_sentence_embedding\n",
    "\n",
    "    return np.array(sentence_embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T08:55:43.397048Z",
     "start_time": "2024-04-19T08:55:43.394616Z"
    }
   },
   "id": "5c5da53988304430"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "sentence_emb_train = generate_embeddings(filtered_sentence_train)\n",
    "sentence_emb_val = generate_embeddings(filtered_sentence_val)\n",
    "sentence_emb_test = generate_embeddings(filtered_sentence_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T08:55:55.509333Z",
     "start_time": "2024-04-19T08:55:43.397256Z"
    }
   },
   "id": "da15d873e05257d2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd188fee960bee91"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(max_iter=10000)\n",
    "\n",
    "lr.fit(sentence_emb_train, y_train)\n",
    "ypred = lr.predict(sentence_emb_val)\n",
    "print(f1_score(ypred, y_val))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8e5594c43097a5e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SVM"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8a709e2aff9975c"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "\n",
    "scaler = StandardScaler()\n",
    "sentence_emb_train_scaled = scaler.fit_transform(sentence_emb_train)\n",
    "sentence_emb_val_scaled = scaler.transform(sentence_emb_val)\n",
    "\n",
    "svm_model = svm.SVC(max_iter=10000)\n",
    "svm_model.fit(sentence_emb_train_scaled, y_train)\n",
    "\n",
    "ypred = svm_model.predict(sentence_emb_val_scaled)\n",
    "print(f1_score(ypred, y_val))\n",
    "\n",
    "sentence_emb_test_scaled = scaler.transform(sentence_emb_test)\n",
    "pred = svm_model.predict(sentence_emb_test_scaled)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T09:12:44.472001Z",
     "start_time": "2024-04-19T09:07:54.870883Z"
    }
   },
   "id": "3c703e850e0e29c2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random Forest Classifier "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54dfec71b7ea38a6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100)\n",
    "rf_model.fit(sentence_emb_train, y_train)\n",
    "ypred = rf_model.predict(sentence_emb_val)\n",
    "print(f1_score(ypred, y_val))\n",
    "pred = rf_model.predict(sentence_emb_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d2980595534c019"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Saving the results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa3260e494aa0c09"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "MODEL_NAME = \"w2v_rf\"\n",
    "model_file_name = MODEL_NAME + \".pt\"\n",
    "\n",
    "with open(\"{}.csv\".format(MODEL_NAME), \"w\") as f:\n",
    "    f.write(\"id,label\\n\")\n",
    "    for i,l in enumerate(pred):\n",
    "        f.write(str(i)+\",\"+str(l) +\"\\n\")\n",
    "    f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T09:20:29.806541Z",
     "start_time": "2024-04-19T09:20:29.792814Z"
    }
   },
   "id": "faeef91330f2ce66"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
